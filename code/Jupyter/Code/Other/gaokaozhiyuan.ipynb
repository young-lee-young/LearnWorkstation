{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45412\n",
      "[]\n",
      "46295\n",
      "[['甘肃', '2017', '理科', '本科一批', '460'], ['甘肃', '2017', '文科', '本科一批', '505'], ['陕西', '2017', '理科', '本科一批', '449'], ['陕西', '2017', '文科', '本科一批', '509'], ['云南', '2017', '理科', '本科一批', '500'], ['云南', '2017', '文科', '本科一批', '555'], ['贵州', '2017', '理科', '本科一批', '456'], ['贵州', '2017', '文科', '本科一批', '545'], ['四川', '2017', '理科', '本科一批', '511'], ['四川', '2017', '文科', '本科一批', '537']]\n"
     ]
    }
   ],
   "source": [
    "#encoding:utf-8\n",
    "\n",
    "#本代码利用selenium和Firefox浏览器对动态网页进行数据请求，用beautifulsoup进行解析，写入Excel文件中\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import xlwt\n",
    "\n",
    "all_list = []\n",
    "def main():\n",
    "    for i in (1,2):\n",
    "        url = 'http://gkcx.eol.cn/soudaxue/queryProvince.html?page={}'.format(i)\n",
    "        getHTML(url)\n",
    "        if(i == 2):\n",
    "            writefile()\n",
    "# url = 'http://gkcx.eol.cn/soudaxue/queryProvince.html?page=1'\n",
    "# getHTML(url)\n",
    "\n",
    "def getHTML(url):\n",
    "# service_args = ['--proxy=localhost:9999','--proxy-type=socks5',]\n",
    "    browser = webdriver.Firefox()\n",
    "    time.sleep(2)\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "    html = browser.page_source\n",
    "    print(len(html))\n",
    "    parserHTML(html)\n",
    "\n",
    "def parserHTML(html):\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    class_lin_seachtable = soup.find('tbody',attrs = {'class':'lin-seachtable'})  \n",
    "    tr_list = class_lin_seachtable.find_all('tr')\n",
    "    for tr in tr_list: \n",
    "        each_list = []\n",
    "        td_list = tr.find_all('td')     \n",
    "        province = td_list[0].get_text()\n",
    "        each_list.append(province)\n",
    "        year = td_list[1].get_text()\n",
    "        each_list.append(year)\n",
    "        ph_or_ch = td_list[2].get_text()\n",
    "        each_list.append(ph_or_ch)\n",
    "        benke = td_list[3].get_text()\n",
    "        each_list.append(benke)\n",
    "        grades = td_list[4].get_text()\n",
    "        each_list.append(grades)\n",
    "        all_list.append(each_list)\n",
    "\n",
    "def writefile():\n",
    "    book = xlwt.Workbook(encoding = 'utf-8',style_compression = 0)\n",
    "    sheet = book.add_sheet('高考志愿',cell_overwrite_ok = True)\n",
    "    col = ('省份','年份','文理','是否本科','分数')\n",
    "    for i in range(0,5):\n",
    "        sheet.write(0,i,col[i])\n",
    "    for i in range(0,len(all_list)):\n",
    "        zhiyuan = all_list[i]\n",
    "        for j in range(0,5):\n",
    "            sheet.write(i+1,j,zhiyuan[j])\n",
    "    book.save('D:/zhiyuan.xls')\n",
    "    print('_________________________________')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
